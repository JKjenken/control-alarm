server:
  port: 2277
spring:
  #Thymeleaf
  thymeleaf:
    mode: LEGACYHTML5
    prefix: classpath:/templates/
    suffix: .html
    template-resolver-order: 0
    cache: false
  #redis 配置
  redis:
    #redis集群配置
    #    cluster:
    #      nodes: namenode1:6379,datanode2:6379,datanode3:6379
    #      password: 123456
    host: 192.168.0.166
    port: 6379
    password: msaredis
    lettuce:
      pool:
        max-wait: 100000  # 连接池最大阻塞等待时间（使用负值表示没有限制）
        max-idle: 8       # 连接池中的最大空闲连接
        min-idle: 0       # 连接池中的最小空闲连接
        max-active: 20    # 连接池最大连接数（使用负值表示没有限制）
    timeout: 5000         # 连接超时时间（毫秒）
    message:
      ship-alarm-user: topic-ship-alarm-user
      ship-alarm-group: topic-ship-alarm-group
      ship-alarm-all: topic-ship-alarm-all
#  kafka:
#    # 指定 kafka 地址可以多个
#    #    bootstrap-servers:
#    #      - 192.168.100.249:9092
#    #      - 192.168.100.249:9093
#    #      - 192.168.100.249:9094
#    bootstrap-servers: 192.168.0.163:9092,192.168.0.169:9092
#    # 指定listener 容器中的线程数，用于提高并发量
#    listener:
#      concurrency: 3
#
#    # 生产者的配置，大部分我们可以使用默认的，这里列出几个比较重要的属性
#    producer:
#      # 每次批量发送消息的数量
#      batch-size: 1000
#      # 设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
#      retries: 0
#      # producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
#      buffer-memory: 33554432
#      # key,value序列化方式
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#
#    # 消费者的配置
#    consumer:
#      # 指定默认消费者group id
#      group-id: test-group
#      # Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
#      auto-offset-reset: latest
#      # 是否开启自动提交
#      enable-auto-commit: true
#      # 自动提交的时间间隔
#      auto-commit-interval: 100
#      # key,value的解码方式
##      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
##      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      websocket:
#        properties:
#          group.id: spring-boot-websocket-consumer-1
# 指定默认topic id
#    template:
#      default-topic: test2
  cloud:
    stream:
      kafka:
        binder:
          brokers: 192.168.0.163:9092,192.168.0.169:9092
      bindings:
        #  =================消费通道=================
        biz-ship-in:
          destination: ship_control_biz
          contentType: application/json
          # 指定消费者组
          group: test-group

        biz-region-in:
          destination: region_control_biz
          contentType: application/json
          # 指定消费者组
          group: test-group
          #与consul 使用时需要指定 binder
      default-binder: kafka
